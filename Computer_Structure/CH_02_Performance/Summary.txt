      Amdahl’s law → Formula that shows the limit of speedup from parallel processing.
      Arithmetic mean (AM) → Average of values (sum ÷ count).
      Base metric → A performance measure under baseline or standard conditions (e.g., SPECspeed base runs).
      Benchmark → Standardized test/program to evaluate system performance.
      
      Clock cycle / tick → One pulse of the system clock.
      Clock cycle time → Duration of one clock cycle (
                                                                          t=1/f).
      Clock rate / speed → Number of cycles per second (Hz).
      Cycles per instruction (CPI) → Average number of cycles an instruction takes.
      Functional mean (FM) → Type of average that weights values based on functionality.
      General-purpose computing on GPU (GPGPU) → Using GPUs (normally for graphics) to perform non-graphics computations.
      Geometric mean (GM) → Multiply values, take the n-th root. Used for benchmarking ratios
      Graphics Processing Unit (GPU) → Processor specialized for parallel graphics and data tasks.
      Harmonic mean (HM) → Reciprocal of the average of reciprocals. Good for rate-based metrics.
      Instruction execution rate → How many instructions are executed per unit time.

                                    Little’s law →                                                                                     L=λ×W.
      Relates concurrency, throughput, and waiting time.
      Many Integrated Core (MIC) → Architecture with dozens/hundreds of cores for parallel tasks (Intel Xeon Phi).
      Microprocessor → A CPU built on a single chip.
      MIPS rate → Millions of instructions per second. (Inadequate metric alone.)
      Multicore → Processors with multiple CPU cores on one chip.
      Peak metric → Best-case performance (theoretical).
      Rate metric → Performance expressed as throughput (operations/sec).
      Reference machine → Standard system used to compare benchmark results.
      Speed metric → Performance expressed as execution time (lower = better).
      SPEC → Standard Performance Evaluation Corporation; provides industry benchmarks.
      System under test (SUT) → The actual system being evaluated.
      Throughput → Number of tasks completed per unit time.


2.1 Obstacles with higher clock speed & logic density

            As we increase clock speed (GHz) and pack more transistors per chip (logic density):
            Heat dissipation – Higher frequency = higher switching activity = more heat. Too much heat damages circuits.
            Power consumption – Power ∝ Frequency × Voltage². Faster chips need more voltage, leading to an exponential rise in energy.
            Signal propagation delay – Wires on the chip take time to send signals (speed of light limits). At very high frequencies, signals may not settle before the next clock tick.
            Synchronization issues – Multiple parts of a large chip may not stay in sync at ultra-high speeds, causing errors.
            ⚡ Insight: This is why chipmakers shifted focus from increasing frequency → to parallelism (multicore).

2.2 Advantages of cache

            Cache is fast memory close to the CPU.
            Faster memory access – L1/L2/L3 caches are orders of magnitude faster than main memory (nanoseconds vs hundreds of ns).
            Reduces average memory latency – CPU doesn’t stall as often waiting for DRAM.
            Bridges CPU–memory gap – Memory speeds haven’t scaled with CPU speeds. Cache smooths this imbalance.
            
            ⚡ Without cache, CPUs would spend most of their time idle waiting for data.

2.3 Methods to increase processor speed
            
            How designers make CPUs faster beyond just clock speed:
            Pipelining – Break instruction execution into stages (fetch, decode, execute, writeback). Multiple instructions overlap. Like an assembly line.
            Superscalar execution – Multiple instructions issued per cycle if independent (parallel execution units).
            Multicore architecture – Instead of one super-fast core, have multiple cores working in parallel.
            Speculative execution & branch prediction – CPU predicts future paths of programs and executes ahead of time. If correct, saves time; if wrong, discard.
            Larger/faster caches – Reduces stalls, improves throughput.
            ⚡ Together, these techniques improve IPC (instructions per cycle), not just raw GHz.

2.4 Obstacles at high clock speed/density
            
            Even with advanced designs:
            Power & heat issues – Thermal limits cap frequency. Cooling is expensive.
            Diminishing returns – Doubling frequency doesn’t double performance (because CPI, memory delays, etc.).
            Memory bottlenecks – CPUs get faster, but DRAM hasn’t kept up → stalls.
            Wire delays – As chips get bigger, interconnect delays dominate.
            ⚡ Moore’s Law (transistors double every ~2 years) slowed down due to these limits.
2.5 Clock rate definition

            Clock rate (clock speed) = cycles per second (Hz).
            Example: 3 GHz = 3 billion cycles per second.
            Same as frequency of CPU’s system clock
            ⚠ But → Not a full measure of performance. One 3 GHz CPU can be slower than another 2 GHz CPU if CPI is worse.

2.6 Why MIPS/FLOPS are inadequate

            MIPS (Million Instructions per Second):
            Doesn’t reflect instruction complexity (some CPUs need more cycles per instruction).
            Different instruction sets = unfair comparisons.

FLOPS (Floating-Point Ops/sec):     
            Useful only for floating-point heavy workloads (scientific/AI).
            Doesn’t represent general-purpose performance.

⚡ Example: A CPU with high MIPS may perform worse if each instruction does less useful work

2.8 Variables in Little’s Law
                  L=λ×W

            L (Length): Average number of items in system (e.g., requests in queue, instructions in pipeline).
            λ (Arrival Rate): Average input rate (items per unit time).
            W (Waiting Time): Average time item spends in the system.
            ⚡ Example: If a server processes 100 requests/sec (
            
            L=100×0.2=20

            Execution time (T): 
                                                                  𝑇   = Instruction count    X  CPI   X  Clock cycle time
            Instruction count × CPI × Clock cycle time



1. Execution rate (instructions per second)
Execution rate =                Instruction count /
                                                 /  Execution time


2. MIPS (Millions of Instructions per Second)
		Now, to express that same execution rate in millions:

									MIPS  =    	Instruction count /
																 /	Execution time × 10^6

	​

	
Amdahl’s Law — Easy Definition

Amdahl’s Law tells us:

👉 The maximum speedup from parallel processing is limited by the portion of a program that cannot be parallelized.

Even with infinite processors, the serial part is a bottleneck.

Formula:


Speedup(N)=  1   /  F +{ (1−f)/N } 
			

1
	​
​
