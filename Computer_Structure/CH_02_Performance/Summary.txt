      Amdahlâ€™s law â†’ Formula that shows the limit of speedup from parallel processing.
      Arithmetic mean (AM) â†’ Average of values (sum Ã· count).
      Base metric â†’ A performance measure under baseline or standard conditions (e.g., SPECspeed base runs).
      Benchmark â†’ Standardized test/program to evaluate system performance.
      
      Clock cycle / tick â†’ One pulse of the system clock.
      Clock cycle time â†’ Duration of one clock cycle (
                                                                          t=1/f).
      Clock rate / speed â†’ Number of cycles per second (Hz).
      Cycles per instruction (CPI) â†’ Average number of cycles an instruction takes.
      Functional mean (FM) â†’ Type of average that weights values based on functionality.
      General-purpose computing on GPU (GPGPU) â†’ Using GPUs (normally for graphics) to perform non-graphics computations.
      Geometric mean (GM) â†’ Multiply values, take the n-th root. Used for benchmarking ratios
      Graphics Processing Unit (GPU) â†’ Processor specialized for parallel graphics and data tasks.
      Harmonic mean (HM) â†’ Reciprocal of the average of reciprocals. Good for rate-based metrics.
      Instruction execution rate â†’ How many instructions are executed per unit time.

                                    Littleâ€™s law â†’                                                                                     L=Î»Ã—W.
      Relates concurrency, throughput, and waiting time.
      Many Integrated Core (MIC) â†’ Architecture with dozens/hundreds of cores for parallel tasks (Intel Xeon Phi).
      Microprocessor â†’ A CPU built on a single chip.
      MIPS rate â†’ Millions of instructions per second. (Inadequate metric alone.)
      Multicore â†’ Processors with multiple CPU cores on one chip.
      Peak metric â†’ Best-case performance (theoretical).
      Rate metric â†’ Performance expressed as throughput (operations/sec).
      Reference machine â†’ Standard system used to compare benchmark results.
      Speed metric â†’ Performance expressed as execution time (lower = better).
      SPEC â†’ Standard Performance Evaluation Corporation; provides industry benchmarks.
      System under test (SUT) â†’ The actual system being evaluated.
      Throughput â†’ Number of tasks completed per unit time.


2.1 Obstacles with higher clock speed & logic density

            As we increase clock speed (GHz) and pack more transistors per chip (logic density):
            Heat dissipation â€“ Higher frequency = higher switching activity = more heat. Too much heat damages circuits.
            Power consumption â€“ Power âˆ Frequency Ã— VoltageÂ². Faster chips need more voltage, leading to an exponential rise in energy.
            Signal propagation delay â€“ Wires on the chip take time to send signals (speed of light limits). At very high frequencies, signals may not settle before the next clock tick.
            Synchronization issues â€“ Multiple parts of a large chip may not stay in sync at ultra-high speeds, causing errors.
            âš¡ Insight: This is why chipmakers shifted focus from increasing frequency â†’ to parallelism (multicore).

2.2 Advantages of cache

            Cache is fast memory close to the CPU.
            Faster memory access â€“ L1/L2/L3 caches are orders of magnitude faster than main memory (nanoseconds vs hundreds of ns).
            Reduces average memory latency â€“ CPU doesnâ€™t stall as often waiting for DRAM.
            Bridges CPUâ€“memory gap â€“ Memory speeds havenâ€™t scaled with CPU speeds. Cache smooths this imbalance.
            
            âš¡ Without cache, CPUs would spend most of their time idle waiting for data.

2.3 Methods to increase processor speed
            
            How designers make CPUs faster beyond just clock speed:
            Pipelining â€“ Break instruction execution into stages (fetch, decode, execute, writeback). Multiple instructions overlap. Like an assembly line.
            Superscalar execution â€“ Multiple instructions issued per cycle if independent (parallel execution units).
            Multicore architecture â€“ Instead of one super-fast core, have multiple cores working in parallel.
            Speculative execution & branch prediction â€“ CPU predicts future paths of programs and executes ahead of time. If correct, saves time; if wrong, discard.
            Larger/faster caches â€“ Reduces stalls, improves throughput.
            âš¡ Together, these techniques improve IPC (instructions per cycle), not just raw GHz.

2.4 Obstacles at high clock speed/density
            
            Even with advanced designs:
            Power & heat issues â€“ Thermal limits cap frequency. Cooling is expensive.
            Diminishing returns â€“ Doubling frequency doesnâ€™t double performance (because CPI, memory delays, etc.).
            Memory bottlenecks â€“ CPUs get faster, but DRAM hasnâ€™t kept up â†’ stalls.
            Wire delays â€“ As chips get bigger, interconnect delays dominate.
            âš¡ Mooreâ€™s Law (transistors double every ~2 years) slowed down due to these limits.
2.5 Clock rate definition

            Clock rate (clock speed) = cycles per second (Hz).
            Example: 3 GHz = 3 billion cycles per second.
            Same as frequency of CPUâ€™s system clock
            âš  But â†’ Not a full measure of performance. One 3 GHz CPU can be slower than another 2 GHz CPU if CPI is worse.

2.6 Why MIPS/FLOPS are inadequate

            MIPS (Million Instructions per Second):
            Doesnâ€™t reflect instruction complexity (some CPUs need more cycles per instruction).
            Different instruction sets = unfair comparisons.

FLOPS (Floating-Point Ops/sec):     
            Useful only for floating-point heavy workloads (scientific/AI).
            Doesnâ€™t represent general-purpose performance.

âš¡ Example: A CPU with high MIPS may perform worse if each instruction does less useful work

2.8 Variables in Littleâ€™s Law
                  L=Î»Ã—W

            L (Length): Average number of items in system (e.g., requests in queue, instructions in pipeline).
            Î» (Arrival Rate): Average input rate (items per unit time).
            W (Waiting Time): Average time item spends in the system.
            âš¡ Example: If a server processes 100 requests/sec (
            
            L=100Ã—0.2=20

            Execution time (T): 
                                                                  ğ‘‡   = InstructionÂ count    X  CPI   X  ClockÂ cycleÂ time
            Instruction count Ã— CPI Ã— ClockÂ cycleÂ time



1. Execution rate (instructions per second)
ExecutionÂ rate =                InstructionÂ count /
                                                 /  ExecutionÂ time


2. MIPS (Millions of Instructions per Second)
		Now, to express that same execution rate in millions:

									MIPS  =    	InstructionÂ count /
																 /	ExecutionÂ time Ã— 10^6

	â€‹

	
Amdahlâ€™s Law â€” Easy Definition

Amdahlâ€™s Law tells us:

ğŸ‘‰ The maximum speedup from parallel processing is limited by the portion of a program that cannot be parallelized.

Even with infinite processors, the serial part is a bottleneck.

Formula:


Speedup(N)=  1   /  F +{ (1âˆ’f)/N } 
			

1
	â€‹
â€‹
