      Amdahl‚Äôs law ‚Üí Formula that shows the limit of speedup from parallel processing.
      Arithmetic mean (AM) ‚Üí Average of values (sum √∑ count).
      Base metric ‚Üí A performance measure under baseline or standard conditions (e.g., SPECspeed base runs).
      Benchmark ‚Üí Standardized test/program to evaluate system performance.
      
      Clock cycle / tick ‚Üí One pulse of the system clock.
      Clock cycle time ‚Üí Duration of one clock cycle (
                                                                          t=1/f).
      Clock rate / speed ‚Üí Number of cycles per second (Hz).
      Cycles per instruction (CPI) ‚Üí Average number of cycles an instruction takes.
      Functional mean (FM) ‚Üí Type of average that weights values based on functionality.
      General-purpose computing on GPU (GPGPU) ‚Üí Using GPUs (normally for graphics) to perform non-graphics computations.
      Geometric mean (GM) ‚Üí Multiply values, take the n-th root. Used for benchmarking ratios
      Graphics Processing Unit (GPU) ‚Üí Processor specialized for parallel graphics and data tasks.
      Harmonic mean (HM) ‚Üí Reciprocal of the average of reciprocals. Good for rate-based metrics.
      Instruction execution rate ‚Üí How many instructions are executed per unit time.

                                    Little‚Äôs law ‚Üí                                                                                     L=Œª√óW.
      Relates concurrency, throughput, and waiting time.
      Many Integrated Core (MIC) ‚Üí Architecture with dozens/hundreds of cores for parallel tasks (Intel Xeon Phi).
      Microprocessor ‚Üí A CPU built on a single chip.
      MIPS rate ‚Üí Millions of instructions per second. (Inadequate metric alone.)
      Multicore ‚Üí Processors with multiple CPU cores on one chip.
      Peak metric ‚Üí Best-case performance (theoretical).
      Rate metric ‚Üí Performance expressed as throughput (operations/sec).
      Reference machine ‚Üí Standard system used to compare benchmark results.
      Speed metric ‚Üí Performance expressed as execution time (lower = better).
      SPEC ‚Üí Standard Performance Evaluation Corporation; provides industry benchmarks.
      System under test (SUT) ‚Üí The actual system being evaluated.
      Throughput ‚Üí Number of tasks completed per unit time.


2.1 Obstacles with higher clock speed & logic density

            As we increase clock speed (GHz) and pack more transistors per chip (logic density):
            Heat dissipation ‚Äì Higher frequency = higher switching activity = more heat. Too much heat damages circuits.
            Power consumption ‚Äì Power ‚àù Frequency √ó Voltage¬≤. Faster chips need more voltage, leading to an exponential rise in energy.
            Signal propagation delay ‚Äì Wires on the chip take time to send signals (speed of light limits). At very high frequencies, signals may not settle before the next clock tick.
            Synchronization issues ‚Äì Multiple parts of a large chip may not stay in sync at ultra-high speeds, causing errors.
            ‚ö° Insight: This is why chipmakers shifted focus from increasing frequency ‚Üí to parallelism (multicore).

2.2 Advantages of cache

            Cache is fast memory close to the CPU.
            Faster memory access ‚Äì L1/L2/L3 caches are orders of magnitude faster than main memory (nanoseconds vs hundreds of ns).
            Reduces average memory latency ‚Äì CPU doesn‚Äôt stall as often waiting for DRAM.
            Bridges CPU‚Äìmemory gap ‚Äì Memory speeds haven‚Äôt scaled with CPU speeds. Cache smooths this imbalance.
            
            ‚ö° Without cache, CPUs would spend most of their time idle waiting for data.

2.3 Methods to increase processor speed
            
            How designers make CPUs faster beyond just clock speed:
            Pipelining ‚Äì Break instruction execution into stages (fetch, decode, execute, writeback). Multiple instructions overlap. Like an assembly line.
            Superscalar execution ‚Äì Multiple instructions issued per cycle if independent (parallel execution units).
            Multicore architecture ‚Äì Instead of one super-fast core, have multiple cores working in parallel.
            Speculative execution & branch prediction ‚Äì CPU predicts future paths of programs and executes ahead of time. If correct, saves time; if wrong, discard.
            Larger/faster caches ‚Äì Reduces stalls, improves throughput.
            ‚ö° Together, these techniques improve IPC (instructions per cycle), not just raw GHz.

2.4 Obstacles at high clock speed/density
            
            Even with advanced designs:
            Power & heat issues ‚Äì Thermal limits cap frequency. Cooling is expensive.
            Diminishing returns ‚Äì Doubling frequency doesn‚Äôt double performance (because CPI, memory delays, etc.).
            Memory bottlenecks ‚Äì CPUs get faster, but DRAM hasn‚Äôt kept up ‚Üí stalls.
            Wire delays ‚Äì As chips get bigger, interconnect delays dominate.
            ‚ö° Moore‚Äôs Law (transistors double every ~2 years) slowed down due to these limits.
2.5 Clock rate definition

            Clock rate (clock speed) = cycles per second (Hz).
            Example: 3 GHz = 3 billion cycles per second.
            Same as frequency of CPU‚Äôs system clock
            ‚ö† But ‚Üí Not a full measure of performance. One 3 GHz CPU can be slower than another 2 GHz CPU if CPI is worse.

2.6 Why MIPS/FLOPS are inadequate

            MIPS (Million Instructions per Second):
            Doesn‚Äôt reflect instruction complexity (some CPUs need more cycles per instruction).
            Different instruction sets = unfair comparisons.

FLOPS (Floating-Point Ops/sec):     
            Useful only for floating-point heavy workloads (scientific/AI).
            Doesn‚Äôt represent general-purpose performance.

‚ö° Example: A CPU with high MIPS may perform worse if each instruction does less useful work

2.8 Variables in Little‚Äôs Law
                  L=Œª√óW

            L (Length): Average number of items in system (e.g., requests in queue, instructions in pipeline).
            Œª (Arrival Rate): Average input rate (items per unit time).
            W (Waiting Time): Average time item spends in the system.
            ‚ö° Example: If a server processes 100 requests/sec (
            
            L=100√ó0.2=20

            Execution time (T): 
                                                                  ùëá   = Instruction¬†count    X  CPI   X  Clock¬†cycle¬†time
            Instruction count √ó CPI √ó Clock¬†cycle¬†time
